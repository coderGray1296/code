### GBDT + LR 进行CTR预测
[GBDT+LR融合方案实战](https://zhuanlan.zhihu.com/p/37522339)

[GBDT+LR算法解析及Python实现](https://www.cnblogs.com/wkang/p/9657032.html)

[GBDT训练实例及调用参数详解](https://www.cnblogs.com/pinard/p/6143927.html)

**GBDT前面的树，特征分裂主要体现对多数样本有区分度的特征；后面的树，主要体现的是经过前N颗树，残差仍然较大的少数样本。优先选用在整体上有区分度的特征，再选用针对少数样本有区分度的特征，思路更加合理，这应该也是用GBDT的原因。**

**GBDT有两种实现方式**

- Scikit-learn.ensemble.GradientBoostingClassifier
- 利用lgb里的params={ 'boosting_type': 'gbdt' }参数

##### 为什么要做离散特征的one-hot？
1. 使用one-hot编码，将离散特征的取值扩展到了欧式空间，离散特征的某个取值就对应欧式空间的某个点。将离散特征通过one-hot编码映射到欧式空间，是因为，**在回归，分类，聚类等机器学习算法中，特征之间距离的计算或相似度的计算是非常重要的**，而我们常用的距离或相似度的计算都是在欧式空间的相似度计算，计算余弦相似性，基于的就是欧式空间。
2. **将离散型特征使用one-hot编码，确实会让特征之间的距离计算更加合理**。比如，有一个离散型特征，代表工作类型，该离散型特征，共有三个取值，不使用one-hot编码，其表示分别是x_1 = (1), x_2 = (2), x_3 = (3)。两个工作之间的距离是，(x_1, x_2) = 1, d(x_2, x_3) = 1, d(x_1, x_3) = 2。那么x_1和x_3工作之间就越不相似吗？显然这样的表示，计算出来的特征的距离是不合理。那如果使用one-hot编码，则得到x_1 = (1, 0, 0), x_2 = (0, 1, 0), x_3 = (0, 0, 1)，那么两个工作之间的距离就都是sqrt(2).即每两个工作之间的距离是一样的，显得更合理。


##### 分桶策略
1.离散化的常用方法是分桶

- 将所有样本在连续的数值属性 j 的取值从小到大排列 a0,a1,a2,...,aN
- 然后从小到大依次选择分桶边界 b1,b2,...,bM 。其中：M为分桶的数量，它是一个超参数，需要人工指定；每个桶的大小 bk-b(k-1) 也是一个超参数，需要人工指定
- 给定属性 j 的取值ai对其分桶：1.若ai < b1,则分桶编号是 0。分桶后的属性的取值为 0; 2.若bk<=ai<=bk+1，则分桶编号是 k。分桶后的属性取值是 k；3.若ai >= bM，则分桶编号是 M。分桶后的属性取值是 M

2.分桶的数量和边界通常需要人工指定。一般有两种方法：
- **根据业务领域的经验来指定**。如：对年收入进行分桶时，根据 2017 年全国居民人均可支配收入约为 2.6 万元，可以选择桶的数量为5。其中：
收入小于 1.3 万元（人均的 0.5 倍），则为分桶 0 。
年收入在 1.3 万元 ～5.2 万元（人均的 0.5～2 倍），则为分桶 1 。
年收入在 5.3 万元～26 万元（人均的 2 倍～10 倍），则为分桶 2 。
年收入在 26 万元～260 万元（人均的 10 倍～100 倍），则为分桶 3 。
年收入超过 260 万元，则为分桶 4 。
- **根据模型指定**。根据具体任务来训练分桶之后的数据集，通过超参数搜索来确定最优的分桶数量和分桶边界。

3.选择分桶大小时，有一些经验指导：
- **分桶大小必须足够小**，小到足够能区分数据，进行分层
- **分桶大小必须足够大，使每个桶内都有足够的样本**。如果桶内样本太少，则随机性太大，不具有统计意义上的说服力。
- 每个桶内的样本尽量**分布均匀**。

##### 参数 超参数 及 超参数的优化方法

**参数与超参数**

按照搜集到的资料来看，其实模型中可以分为两种参数，一种是在训练过程中学习到的参数，即parameter也就是上面公式里的w（fx = WX + b线性回归），而另一种参数则是hyperparameter，这种参数是模型中学习不到的，是我们预先定义的，而模型的调参其实指的是调整hyperparameter，而且不同类型的模型的hyperparameter也不尽相同，比如SVM中的C,树模型中的深度、叶子数以及比较常规的学习率等等，这种参数是在模型训练之前预先定义的，所以关于模型的选择其实更多的指的是选择最佳的hyperparameter组合。

总体来说：
- 参数：就是模型可以根据数据可以自动学习出的变量，应该就是参数。比如，深度学习的权重，偏差等
- 超参数：就是用来确定模型的一些参数，超参数不同，模型是不同的(这个模型不同的意思就是有微小的区别，比如假设都是CNN模型，如果层数不同，模型不一样，虽然都是CNN模型哈。)，超参数一般就是根据经验确定的变量。在深度学习中，超参数有：学习速率，迭代次数，层数，每层神经元的个数等等。

**超参数的搜索方法**

一般调优超参数都是组合着来，和相关联的特征组合一起，分组进行。如 GBDT中的学习率/步长 和 最大迭代次数是相关联的，需要共同迭代，取最优的超参数

1.网格搜索法 grid search

**网格搜索(grid search)** 是最基本的黑盒优化方法,其也被称为全因子设计(full factorial design).用户为每一个要优化的参数执行一个有限的值集,然后在这些参数的**笛卡尔积/排列组合**所构成的网格上进行性能评估.因为需要评估的次数随参数数量的增加呈现指数增长,因此这种方法很难被用到参数数量多的高维黑盒优化场合.此外我们若对网格取得非常密集(每个参数对应的取值集合的基数过大),则在参数数量不多的情形下也需要庞大的计算代价.

网格搜索是在所有候选的参数选择中，通过循环遍历，尝试每一种可能性，表现最好的参数就是最终的结果（暴力搜索）。

原理：在一定的区间内，通过循环遍历，尝试每一种可能性，并计算其约束函数和目标函数的值，对满足约束条件的点，逐个比较其目标函数的值，将坏的点抛弃，保留好的点，最后便得到最优解的近似解。

为了评价每次选出的参数的好坏，我们需要选择评价指标，评价指标可以根据自己的需要选择accuracy、f1-score、f-beta、percision、recall等。

**同时，为了避免初始数据的划分对结果的影响，我们需要采用交叉验证的方式来减少偶然性，一般情况下网格搜索需要和交叉验证相结合使用。**

python的sklearn包中网格搜索函数GridSearchCV：
```
GridSearchCV(
estimator,param_grid, scoring=None, fit_params=None, n_jobs=1, iid=True,
refit=True,cv=None, verbose=0, pre_dispatch='2*n_jobs',
error_score='raise',return_train_score=True)
```
- estimator：所使用的分类器
- param_grid：值为字典或者列表，需要最优化的参数的取值范围，如paramters = {'n_estimators':range(10,100,10)}。
- scoring :准确度评价指标，默认None,这时需要使用score函数；或者如scoring='roc_auc'。
- fit_params:字典类型数据，主要用于给fit方法传递参数。
- n_jobs: 并行数，int：个数,-1：跟CPU核数一致, 1:默认值。
- cv :交叉验证参数，默认None，使用三折交叉验证。指定fold数量，默认为3，也可以是yield训练/测试数据的生成器。
- refit :默认为True,程序将会以交叉验证训练集得到的最佳参数，重新对所有可用的训练集与验证集进行训练，作为最终用于性能评估的最佳模型参数。即在搜索参数结束后，用最佳参数结果再次fit一遍全部数据集。
- return_train_score:布尔类型数据，默认为Ture ,为False时交叉验证的结果不包含训练得分。

2.随机搜索法 random search

一个简单的可以替代网格搜索的方法是**随机搜索(random search)** 。顾名思义,随机搜索在参数的可能取值中随机抽出来进行性能评估,知道我们给定的计算资源耗尽为止.当其中一些参数比另一些参数重要得多时,随机搜索算法往往比网格搜索方法更有效.只管上来说,当我们对 N 个参数总共进行 B 次性能评价时,网格搜索只能对每个参数只能评价其在 B^1/N 个位置上的性能,而随机搜索则能对每个点都评估其取 B 个不同值的性能.这一示意图如图3所示。

![avatar](https://github.com/coderGray1296/code/blob/master/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%A4%8D%E4%B9%A0/pictures/CTR_1.png)

由于随机搜索算法没有对机器学习算法进行任何假设并且在给定足够的计算资源的情况下其能够逼近模型的最优解,因此其是评价一个黑盒优化算法的一个有用的基准线.随机搜索算法常常与更复杂的优化算法相结合来提升算法的收敛速率以及增加模型的探索性.由于随机优化算法能够对整个参数空间进行搜索,因此其常被用来初始化一些更为复杂的算法.

原理：在一定的区间内，不断随机地而不是有倾向性产生随机点，并计算其约束函数和目标函数的值，对满足约束条件的点，逐个比较其目标函数的值，将坏的点抛弃，保留好的点，最后便得到最优解的近似解。

这种方法是建立在概率论的基础上，所取随机点越多，则得到最优解的概率也就越大。这种方法存在精度较差的问题，找到近似最优解的效率高于网格搜索。**随机搜索一般用于粗选或普查**。

python的sklearn包中随机搜索函数RandomizedSearchCV：
```
RandomizedSearchCV(estimator, param_distributions, n_iter=10, scoring=None,
fit_params=None, n_jobs=1, iid=True, refit=True, cv=None, verbose=0,
pre_dispatch=‘2*n_jobs’, random_state=None, error_score=’raise’)
```
- param_distributions：值为字典或者列表，需要最优化的参数的取值范围，同时需要选择一种rvs（产生服从指定分布的随机数）方法来进行抽样，比如scipy.stats.distributions
- random_state:随机种子，默认为None,int类型或者随机状态实例，伪随机数生成器状态用于从可能的值列表而不是scipy中随机抽样。统计分布。如果int，随机状态是随机数生成器所使用的种子;如果随机状态实例，随机状态是随机数生成器;如果没有，随机数生成器是np.random所使用的随机状态实例。
- error_score: 默认为raise，可选择参数numeric，在模型拟合过程中如果产生误差，在raise情况下，误差分数将会提高，如果选择numeric，则fitfailedwarning会提高。

3.贝叶斯策略SMBO算法

贝叶斯策略建立了一个代理模型，试图从超参数配置中预测我们所关注的度量指标。在每一次的迭代中，我们对代理会变得越来越有信心，新的猜测会带来新的改进，就像其它搜索策略一样，它也会等到耗尽资源的时候终止。

![avatar](https://github.com/coderGray1296/code/blob/master/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%A4%8D%E4%B9%A0/pictures/CTR_2.png)

**高斯过程**
我们可以将高斯过程定义为学习从超参数配置到度量映射的替代过程。它不仅产生一个预测值，而且还会给我们一个不确定性的范围。

![avatar](https://github.com/coderGray1296/code/blob/master/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%A4%8D%E4%B9%A0/pictures/CTR_3.png)

在上图中，我们在单个变量上（在横轴上）遵循高斯过程优化的第一步，在这个例子中，可以代表Learning Rate或Dropout Rate。在纵轴上，我们将某个度量指标绘制成单个超参数的函数。由于我们正在寻找尽可能低的值，所以可以把它看作是损失函数。
图中黑线代表了训练出来的模型，红线是真实值，也就是我们正在试图学习的函数。黑线代表我们对真实值函数假设的平均值，而灰色区域表明空间中相关的不确定性或方差。正如我们看到的，点周围的不确定性减少了，因为我们对这些点周围的结果非常有信心，因为我们已经在这里训练了模型。而在信息较少的区域，不确定性会增加。
现在已经定义了起点，我们准备好选择下一个变量来训练模型。为此，需要定义一个采集函数，它会告诉我们在哪里采样下一个配置。
在这个例子中，如果我们使用不确定性区域中的配置，则函数将寻找尽可能低的值。上图中的蓝点显示了下一次训练所选择的点。

![avatar](https://github.com/coderGray1296/code/blob/master/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%A4%8D%E4%B9%A0/pictures/CTR_4.png)

我们训练的模型越多，代理对下一个采样的点就越有信心。下图是8次训练后的模型:

![avatar](https://github.com/coderGray1296/code/blob/master/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%A4%8D%E4%B9%A0/pictures/CTR_5.png)

高斯过程属于一类称为基于序列模型的优化(SMBO)的算法。正如刚刚看到的，这些算法为搜索最佳超参数配置提供了非常好的基准。

**方法对比**

![avatar](https://github.com/coderGray1296/code/blob/master/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%A4%8D%E4%B9%A0/pictures/CTR_6.png)
