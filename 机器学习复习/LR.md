### LR (Logistic Regression)
分为两部分：
- 理论推导
- 实际应用

#### 一、逻辑回归简介
逻辑回归（LR,Logistic Regression）是传统机器学习中的一种分类模型，由于LR算法具有简单、高效、易于并行且在线学习（动态扩展）的特点，在工业界具有非常广泛的应用。
>LR属于一种在线学习算法，可以利用新的数据对各个特征的权重进行更新，而不需要重新利用历史数据训练。

**明明是回归，为什么都用于分类问题呢？**
这就要提到线性回归，下面介绍一下线性回归先～
###### 线性回归
概念：对于多维空间中存在的样本点，我们用特征的线性组合（特征加权）去拟合空间中点的分布和轨迹。
有监督训练数据集（X,Y），X表示特征，Y表示标签，w表示该某一特征对应的权重，最终的线性模型如hw(x)所示：
![avatar](https://github.com/coderGray1296/NLP/blob/master/ELMo/pictures/3.jpg)
线性回归模型既可以用于回归，也可以用于分类。
- 对于回归问题，显而易见就是拟合
- 对于分类问题，则显得有些困难，由于输出的值没有范围，即使使用阈值划分分类区间，也不会有很好的鲁棒性
从而引出引出主角 -- 逻辑回归
>[逻辑回归是假设数据服从Bernoulli分布，因此LR属于参数模型] 后续会对比svm解释何为参数模型

**在线性回归的拟合基础上，我们希望找到一个越阶函数来实现到某个区间内值的映射，从而适应分类任务**
这个函数就是sigmoid：$\Phi(z) = \frac{1}{1+e^{-z}}$
![avatar](https://github.com/coderGray1296/NLP/blob/master/ELMo/pictures/3.jpg)
有了sigmoid函数之后，取值就在[0,1]之间了，我们也可以将函数值视为类为1的后验概率 p(y=1|x),也就是有一个x，通过sigmoid函数计算出来这个x属于类别1的概率大小。于是自然的，将函数值大于等于0.5的归到类别1，小于0.5的归到类别0
- $\hat{y} = 1, if\quad\Phi(z)>=0.5$
- $\hat{y} = 0, otherwise$

#### 二、逻辑回归的目标函数及极大似然估计
